
cuda 프로그래밍 --> llm을 만들기 위한 라이브러리...개발 환경이다. 거의 아나콘다 급이다. 

텐서플로어, 파이토치 --> 플랫폼이다. 둘 중 하나만 설치해야한다. 


쿠다 프로그래밍을 설치하기 위해 파이토치 플랫폼을 설치해야한다. 


내 pc에 cuda를 설치하려고 해. 지금 현재 아나콘다는 이미 설치되어 있어. 내 pc의 gpu 버전과 cuda 버전의 호환성을 잘 모르겠어. 내 pc의 gpu 버전 확인하는 방법을 알려줘.


장치관리자 들어가서 --> 디스플레이 어댑터 --> 확인

![[Pasted image 20250611153358.png]]

쿠다는 안바뀌고 파이토치 상태만 바뀐다. 쿠다는 툴이다.



rtx 2080 에 호환성을 갖는 쿠다 버전 알려줘. --> 쿠다 11.8 버전 다운로드하기!

### slm 개발 환경 구축
설치해야할 것
1. 아나콘다 설치하기
2. 쿠다 버전 설치하기(window 11, rtx2080에 맞춰서....11.8v 설치)
3. cuDNN 설치하기(쿠다 11.8v과 맞춰서 설치하기)
4. 쿠다에 있는 파일 cuDNN으로 옮기기
5. pytorch 설치하기
	1. 아나콘다 프롬프트에서 아래와 같은 방법으로 설치하면 됨
	2.  가상환경 만들기(pytorch_env)
		1. conda create -n pytorch_env python=3.10
		2. - (진행 과정에서 Proceed ([y]/n)? 라고 물어보면 y를 입력하고 엔터를 누르세요.)
	3. 만든 환경 활성화 하기
		1. conda activate pytorch_env
		2. - **가장 중요:** 이 명령어를 실행하면 창의 맨 앞에 있던 **(base)**가 **(pytorch_env)**로 바뀔 겁니다. **꼭 바뀐 것을 확인하세요!**
	4. PyTorch 설치하기**
		1. 이제 (pytorch_env)로 바뀐 것을 확인한 후, 드디어 PyTorch 설치 명령어를 실행합니다.
			1. pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
	5. ### **설치 확인하기 (매우 중요)**
		1.  설치가 끝났으면, 정말로 GPU와 cuDNN을 잘 인식하는지 확인해봐야 합니다.
		2. **(pytorch_env)가 활성화된 상태를 유지**한 채로, 터미널에 python 이라고 입력하고 엔터를 치세요.
		3. 파이썬이 실행되면(>>> 표시), 아래 코드를 한 줄씩 입력하면서 결과를 확인합니다.
```
import torch

# 1. CUDA 사용 가능한지 확인 (True가 나와야 함)
print(f"CUDA available: {torch.cuda.is_available()}")

# 2. cuDNN 사용 가능한지 확인 (True가 나와야 함)
print(f"cuDNN available: {torch.backends.cudnn.is_available()}")

# 3. 설치된 cuDNN 버전 확인
print(f"cuDNN version: {torch.backends.cudnn.version()}")

# 4. 현재 사용 중인 GPU 이름 확인
if torch.cuda.is_available():
    print(f"Current GPU: {torch.cuda.get_device_name(0)}")
```

- **CUDA available: True** 와 **cuDNN available: True** 가 나오면 완벽하게 성공한 것입니다.


### 추가적인 설명
1. 자신의 환경과 맞게 설치하면 된다. (아래 이미지처럼 쿠다 버전 설치하기)
![[Pasted image 20250611161022.png]]
2. cuDNN 인공지능 라이브러리 설치(이건 쿠다의 두뇌역할을 한다.)

![[Pasted image 20250611161944.png]]
3. 쿠다에 있는 파일을 cuDNN에 파일 복사 붙여넣기
4. pythorch 설치 하기
![[Pasted image 20250611172046.png]]


### 결과 분석
3. - CUDA available: True
    
    - 이것은 PyTorch가 사용자님의 NVIDIA GPU를 성공적으로 인식했다는 의미입니다. **가장 중요한 첫 번째 관문을 통과한 것입니다.**
        
- cuDNN available: True
    
    - 방금 어렵게 설치하신 **cuDNN 라이브러리를 PyTorch가 찾아서 딥러닝 연산 가속을 위해 사용할 준비가 되었다**는 뜻입니다. 이것도 완벽합니다.
        
- cuDNN version: 90100
    
    - 사용 중인 cuDNN의 버전까지 정확하게 확인되었습니다.


