
## ✅ n8n = **"n**ode-based **a**utomation" → **n8n**

- **"n" + "8" + "n"** → “n”으로 시작하고 “n”으로 끝나는 단어 중에 **8글자가 생략**된 것을 의미합니다.
    
- 이 방식은 **국제화(i18n)**, **접근성(a11y)** 같은 표기와 유사합니다.
    

|축약어|원래 의미|방식|
|---|---|---|
|**n8n**|**nodemation**|n + 8자 생략 + n|
|**i18n**|**internationalization**|i + 18자 생략 + n|
|**a11y**|**accessibility**|a + 11자 생략 + y|

---

### 🔍 참고: "nodemation"이란?

- **Node + Automation**의 합성어예요.
    
- 즉, **“노드 기반 자동화 도구”**라는 뜻입니다.
    
- n8n은 실제로도 워크플로우를 **노드 기반 GUI**로 구성하고,  
    데이터를 흐름처럼 자동으로 처리할 수 있게 해줍니다.




n8n으로 엣지가 자동으로 연결됨.



보고서 작성과정 중에 중대성평가를 진행하려고 해. 예를 들어 한국중부발전 지속가능경영보고서를 자동화할때, 보고서 초안 작성 중에 중대성 평가를 진행하려고 하는데, 한국중부발전 전체이슈풀을 뽑으려고 할때 국내기업 6군데 벤치마킹을 통해 뽑고, SASB, GRI2021, TCFD, 경영전략, 뉴스 리서치, 법령 등을 ESG 분야에서 크롤링을 해서 핵심이슈를 도출하려고 해. 근데 환경 분야에서 기후변화 대응이라는 이슈가 SASB에서 원하는 이슈일 때 이거를 표시를 해야해. 그런식으로 핵심지표를 뽑으려고 해. 이럴 때 노코딩을 통해서 하려고 하는데 백엔드는 n8n 프레임워크를 사용하려고 하고, 라이브러리를 고민중인데, 라이브러리는 뭘 해야할까?추천해줘

근데 추가적으로 크롤링한 모든 값들을 정규화 과정을 통해 점수를 합산해서 순위를 매겨서 할꺼야.


|기능|사용 노드 (라이브러리 역할)|설명|
|---|---|---|
|🔍 **기업 벤치마킹 (6개사)**|🟩 HTTP Request Node + CSV Parse|기업 6개 웹사이트 or 보고서 크롤링 (FastAPI 기반 크롤러와 연동해도 OK)|
|📚 **SASB / GRI / TCFD 기준 데이터 호출**|🟦 Airtable API / Google Sheets API|각 기준표를 표로 정리 후 연결 가능 (SaaS DB처럼)|
|🧠 **이슈 요약 및 매핑**|🟨 OpenAI Node (GPT-4)|각 문단/문서 요약 + SASB 키워드 매칭|
|📰 **뉴스·법령 크롤링**|🟥 HTTP Request Node|ESG 키워드 기반 뉴스 검색 API, 법령 사이트 크롤링|
|🧩 **지표 연관 표시**|🟦 Function Node|예: `"기후변화 대응"` → `"SASB: ENV-210a"` 표시 로직|
|💾 **이슈풀 저장**|🟪 PostgreSQL Node / Google Sheets|정리된 이슈풀 저장 및 검토|
|📤 **리포트 초안 반환**|🟧 Webhook 응답 Node|프론트로 핵심 이슈 리스트 반환 (Next.js 연동)|




### (프롬프팅) 노코딩을 하려고 해. 개발 툴은 커서 ai이고, 프레임워크는 n8n, mcp로 라이브러리로 관리할꺼야. 엔진은 task master ai를 사용할꺼야.

#### 라이브러리 설치 관리자
- 라이브러리를 수동이냐 자동으로 설치 하는 것
- 엔진: 라이브러리를 자동으로 설치하는 관리자를 의미함 --> 노코딩할 때 사용됨
- pip: 라이브러리를 수동으로 설치하는 관리자를 의미함 --> flask 사용
- requirements.txt: 라이브러리를 입력했음 --> fastAPI에서 사용함



#### TastMaster AI: 엔진이다. --> 노코딩할 때 사용함

- **당신이 정의한 전체 자동화 작업을 "AI가 태스크 단위로 분해, 계획, 실행"하는 상위 오케스트레이터**
	- **여러 개의 작업(task), 서비스(service), 또는 데이터 흐름(data flow)**을 AI나 시스템이 자동으로 조합·계획·실행해주는 지휘자 역할**
    
- GPT 기반 LangChain Agent처럼, **작업을 논리적으로 나눠 실행할 수 있는 AI 컨셉 또는 툴**입니다.





#### makefile 생성(팀끼리 협업할 때, 각 마이크로서비스를 빌드하고자 할때, 즉, docker-compose.yml대신하기 위해..그러므로 docker-compose.yml은 없애고 makefile을 만들어야 함)

1. 프로젝트 루트에 Makefile생성(한줄씩 powershell에서 관리자 권한으로 실행하기)

### **make 명령어 실행방법**
##### 관리자 권한 PowerShell에서 실행  
Set-ExecutionPolicy Bypass -Scope Process -Force      <---여기서부터 파워셀에 입력하면 됨
[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072  
iex ((New-Object System.Net.WebClient).DownloadString('[https://community.chocolatey.org/install.ps1'))](https://community.chocolatey.org/install.ps1'\)\))
##### 설치 후 make 설치  
choco install make
##### make 설치 확인  
make --version
##### Makefile 파일 생성 후 CursorAI에게 
"각 마이크로서비스 컨테이너 이름에 맞게 Makefile에 make명령어를 추가해줘"
라고 프롬프트 입력해주기


#### 해설
N8N 서비스용 Makefile이 생성되었습니다. 이 Makefile에는 다음 기능이 포함되어 있습니다:

1. 기본 명령어:

	- make build: 도커 이미지 빌드
	
	- make run: 도커 컨테이너 실행
	
	- make stop: 도커 컨테이너 중지
	
	- make restart: 도커 컨테이너 재시작
	
	- make clean: 도커 이미지 및 컨테이너 정리
	
	- make dev: 개발 환경에서 직접 실행

2. SCORE 서비스 전용 명령어:

	- make build-score: SCORE 서비스 도커 이미지 빌드
	
	- make run-score: SCORE 서비스 도커 컨테이너 실행
	
	- make stop-score: SCORE 서비스 도커 컨테이너 중지
	
	- make restart-score: SCORE 서비스 도커 컨테이너 재시작

3. 도움말:

	- make help: 사용 가능한 명령어 목록 표시

필요에 따라 추가 마이크로서비스가 있다면 동일한 패턴으로 명령어를 추가할 수 있습니다.



#### mcp json 파일 만들기

1. 위의 코드를 mcp.json에 가져다가 놓기
```
{

    "mcpServers": {

      "claude": {

        "provider": "anthropic",

        "apiKey": "${ANTHROPIC_API_KEY}",

        "model": "claude-3-opus-20240229",

        "apiUrl": "https://api.anthropic.com/v1/messages"

      }

    }

  }
```


2. .env에 아래 줄 추가(이건 키 받아옴)
ANTHROPIC_API_KEY=[YOUR_ANTHROPIC_API_KEY_HERE]


3. main.py에 아래 코드 추가(.env에 있는 클로드 키를 mcp.json에서 @c:\Users\bitcamp\.cursor\mcp.json 다음과 같을 때 어떻게 "${ANTHROPIC_API_KEY}",여기에 값을 주입할 수 있는가? 이거에 대한 답변은 main.py에 아래 코드를 입력하면 된다)

```
import os 
import json 
import re 
from dotenv 
import load_dotenv 


# mcp.json 읽기

with open('mcp.json', 'r') as file:

    content = file.read()

  

# ${...} 패턴 찾아 환경변수로 치환

def env_var_replacer(match):

    var_name = match.group(1)

    return os.getenv(var_name, f"${{{var_name}}}")  # 없으면 그대로 둠

  

content = re.sub(r"\$\{(\w+)\}", env_var_replacer, content)

  

# JSON 객체로 파싱

config = json.loads(content)

  

# 확인

print(config['mcpServers']['claude']['apiKey'])
```

한국남동발전 -2022

![[Pasted image 20250523153046.png]]


한국동서발전 -2024

![[Pasted image 20250523153134.png]]


한국수력원자력
![[Pasted image 20250523153227.png]]


한국전력공사

![[Pasted image 20250523153520.png]]


Rag --> 직접 가져와서 내가 크롤링으로 수동으로 가져오지는 않고, 





ex. 구글AI스튜디오  
1) 퍼스널 랜딩 페이지를 위한 PRD를 만들려고 하는데, 어떤게 필요해?  
2) 기술적으로 내가 잘 모르는데, 현대적으로 가장 트렌디한 기술 스택, 돈이없는 학생 개발자도 할 수 있는 기술 스택 추천해줄래?  nextjs와 superbase를 사용해줘  
3) 작성한 기술 제안서를 prd.md 파일로 저장  
4) 커서AI에게 prd문서를 task master mcp의 parse-prd를 사용해서 example.txt를 참고해서 script/prd.txt를 만들어줘  
subtask 리스트가 생성이 되면, task우선순위를 물어보고 그때부터 차례로 진행








#### platform.openai.com/api-keys
(아래 코드는 api-keys)
[YOUR_OPENAI_API_KEY_HERE]