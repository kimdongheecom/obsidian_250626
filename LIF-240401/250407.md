
크롤링의 분류

- 정적:

- 동적:



f12눌렀을 때, 나오는 것은 html이다. 

아래는 가상 뷰(버츄얼 뷰)라고 할 수 있다.(가짜 세상, 가상..... - 매트릭스로 따지면 빨간약이라고 할 수 있다.) - 
![[Pasted image 20250407093715.png]]


아래가 바로 진짜(리얼 뷰)이다.

![[Pasted image 20250407093736.png]]


### 리엑트로 가서 딥이 되려면.... ?

## 딥한 상태 (Deep State)

- 상태가 중첩된 구조 안에 있고, 여러 레벨로 퍼져 있음
    
- 상태 변경이 여러 컴포넌트 또는 하위 트리 전반에 영향을 줌



### 원본과 공유되냐 독립되냐의 차이

deep copy - 원본이랑 독립되어 있어서 서로 영향을 주고 ㅂ못받는다. 

shallow copy - 원본을 바꾸면  카피본이 바뀐다. 

쉘로우나 딥이나 내부 공유 객체가 있는데, 원본에서 가져온 내부 객체를 정했을 때, 내부 객체가 변했을 때 따라가는게 shallow copy이고, 내부 객체가 변하지 않는게 deep copy이다.  



아래 부분에 코드를 변경하면, 가상 뷰도 또한 바뀐다. 이것을 shallow copy 상태라고 한다. 
![[Pasted image 20250407095617.png]]

![[Pasted image 20250407095653.png]]

백엔드는 deep copy라고 한다. 


크롤링을 두가지로 나누면 정적, 동적의 차이점과 구현 방식은 어떻게 다른가?

### 정적 크롤링 vs 동적 크롤링

정적 크롤링(shallow)
- html 내부에 데이터의 위치가 바로 존재한다.
- 파싱 도구:requests, BeautifulSoup, Lxml 등
- 크롤링 난이도: 낮음
- React로 되어있지 않다.
- 
동적 크롤링(deep)
- js 실행 결과로 dom(가상)에 생성됨.
- deep에서 부터 데이터를 가지고 왔음
- 파싱 도구: Playwright 등
- 크롤링 난이도: 높음
- SPA 기반 페이지이다. 대표 SPA 프레임워크 예시: React, Vue.js이다. React를 쓴다는 것은 원본에 영향을 주지 않는다.
- 사용 예시: SPA 기반 페이지, axios


아침이 되었을 때, 업데이트가 되었으면 좋겠다. 


DB로 보내고 나서, 로그인 했을 때, 


리엑트는 다이나믹으로 움직인다? 이거에 대해 쳇 지피티에 물어보기.


### SPA

**SPA = Single Page Application**

> 하나의 HTML 페이지에서 모든 걸 처리하는 웹 애플리케이션을 의미함. SPA는 **페이지를 새로 안 불러오고**, **필요한 데이터만 바꿔치기**해서 마치 앱처럼 빠르게 동작하는 웹앱이야!

- **한 번만 HTML 받아옴**, 이후엔 **필요한 부분만 바꿔치기**
    
- 페이지 이동해도 화면이 **부드럽고 깜빡이지 않음**  
    🧠 예: 구글 메일(Gmail), React 기반 웹앱

#### 대표 SPA 프레임워크

- React ⚛️
    
- Vue.js
    
- Angular
- 
### 렌더링

**렌더링(rendering)**은 사용자가 볼 수 있도록 **화면에 UI를 그리는 것**이야.  
예를 들어, 버튼, 리스트, 제목 같은 걸 HTML로 만들어서 브라우저에 보여주는 거지.



### 사용자가 사이트에 들어가면 **Top 100 음악 리스트**를 바로 볼 수 있는 웹앱 만들기 흐름 과정

``` 
사이트에 들어가면 **Top 100 음악 리스트**를 바로 볼 수 있는 웹앱 만들기!  
(React + 백엔드 API 기준)

[1] 사용자가 사이트 주소에 들어감 (ex: music.com)
   ↓
[2] HTML 파일 딱 하나(index.html)가 브라우저에 뜸
   ↓
[3] React 앱이 실행됨 (App.jsx)
   ↓
[4] Top100 컴포넌트가 처음으로 '보일 준비'함 (렌더링)
   ↓
[5] Top100 컴포넌트 안에서 '데이터 주세요!' 하고 백엔드에 요청
   ↓
[6] 백엔드가 음악 100개 데이터를 JSON으로 줌
   ↓
[7] React가 그 데이터를 받아서 화면에 예쁘게 보여줌

```


#### 현재 상황

현재 크롤러는 FastAPI 컨테이너로 따로 구성되어 있으며, 
아직 크롤링한 데이터를 데이터베이스(DB)에 저장하지 않고 있습니다. 
앞으로 user 컨테이너와 데이터 연동이 필요해질 것을 고려해, 
두 컨테이너가 같은 DB를 공유하는 구조로 설계할지 검토 중입니다.

현재 크롤러는 FastAPI 기반으로 동작하고 있고, 
크롤링한 데이터를 아직 데이터베이스에 저장하지 않은 상태입니다. 
다만 추후 사용자 컨테이너에서 해당 데이터를 조회할 수 있도록 할 계획이라면, 
두 컨테이너가 같은 데이터베이스를 공유하는 것이 좋다고 판단됩니다. 하지만, 데이터가 많고, 사용자도 많아지면  
**"DB를 공유하는 구조가 병목이 되거나, 아키텍처가 무너지기 시작할 수 있어."** 이제부터는 규모가 커질 경우에 대해 **CQRS 관점**으로 DB를 같은 것을 쓰면 안된다고 해. 그래서 DB를 공유 안하고 분리해야 한다.

CQRS 패턴: 데이터를 많이 저장하는 패턴....

###### 만약 둘이 DB 같이 쓰면?
###### 🧠 user 컨테이너 (읽기 폭주)

- 수천 명이 차트 페이지에 접속해서 DB 조회 쿼리 쏘기 시작, **읽기 전용 DB** (user 전용)
    
###### 🤖 crawler 컨테이너 (쓰기 연산 중)

- 수많은 곡, 아티스트 정보를 저장하고 갱신 중, **쓰기 전용 DB** (crawler 전용)
    
###### 😱 결과

- DB에 **읽기/쓰기 충돌**
    
- I/O 병목, 락(lock) 걸림
    
- 성능 저하, 지연 발생


하지만, 부득이하게, 우리는 DB를 두 개를 못쓴다. 돈을 내야하기 때문에,/.......
코드는 구현 할 수 있지만, 못한다. 결론, DB는 하나만 봐야 한다.
#### 목표

콘솔창에 음악 100개 차트 데이터가 있으면...

라우터에 정해놓은 URL을 띄어놔야한다.

크롤링해서 가져온 데이터를 DB에 저장해야한다. DB는 user 테이블, crawler 테이블 공유할 예정


#### 순서

1. 서비스에서 크롤링 로직을 구현하였다. (지금 동적으로 움직인다. 이 말은 즉슨, 이건 타임 요소가 녹아져 있다. 우리는 동적으로 구현할 것이다. ). SSR로 구현해야한다(고객이 요청안해도 이미 화면이 보여져 있으니까)
2. DB로 보내기 위해 repository로 보내야 한다.(Repository에 쿼리와 커멘드가 있다. 쿼리와 커멘드를 짜려면 entity가 필요하다. MusicEntity가 필요하다. 그러면 쳇 지피티에게 차트 100에 있는 노래 순위, 제목, 가수, 날짜 정보, cross, 정규화된 개념이 필요하다. 이 칼럼에 따라 entity가 만들어진다. DB테이블이 만들어진다. 그리고 entity가 DB에 테이블에 들어간다. )
3. 마지막 보여주는 곳(최종 종착역): 프론트엔드의 컴포넌트이다. 여기에 음악 차트 100개가 있다. 




벡엔드 기술 스팩 - fastAPI, redis, postgresql

### 배포와 업로드의 차이
#### 배포
- 데이터 베이스를 클라우드 서비스에 등록한다. 
- 사용자들 보게 하기 위해 배포하는 것이다.
- 배포되면 브라우저에 노출된다. 컨테이너에 다가 넣는 것은 사용자가 브라우저에 보이게 하려고 한다.  도커는 컨테이너를 브라우저에 바로 보내는 것이다. 근데 지금 당분간 도커 안쓰고 배포할 예정(돈이 없기에)
#### 업로드
- 개발자를 위한 것이다. 나혼자 몰래 볼려고 하는 것이다. 


**프로젝트 현재 상황 및 목표**

- user 컨테이너와 crawler 컨테이너가 db를 같이 공유할 예정
- fastAPI에 DB를 넣을 예정....즉, fastAPI와 DB를 지금까지 분리시켜 왔지만, 분리 안 시킬 예정이다.
- railway에 프로젝트 배포할 예정(일단, crawler 파일만)
### 클라우드 배포 플랫폼: railway (다운 및 설치 방법)
프로젝트를 railway에 배포하려고 한다. 왜냐 무료이고, 우리는 지금까지 nextJS와 fastAPI, DB를 분리시켰다. 하지만, 여기에서는 FastAPI와 DB를 분리안시키고, FastAPI에 DB를 넣을 것이다. 

- 도메인을 쪼개는 이유? --> 몰려버리면 돈이 오버되니까......?(다시 알아보기)
- DB를 railway에 통으로 올려버리면 좋은데... 안 넣을거다. 


1. https://railway.com/new 사이트 접속 및 signin
2. 크롤러 복사본 따로 만들기(.gitignore와 .dockerignore 파일 만들기) --> railway에서는 .env를 올리면 안된다고 함(정책이다.)
3. 지금은 DB를 분리 안시키고(우린 지금까지DB와 fastAPI, nextJS로 분리시켰지만, fastAPI에 DB를 넣었다. 왜냐 돈나가기 때문에. DB를 안에다가 넣으면 통신료가 안나가기 때문에) 
4.  깃허브에 LIF-crawler-fast-v1 파일 커밋하기











5. ![[Pasted image 20250407123952.png]]



#### 질문: 여기에 postgres를 추가하고 싶어.

Render의 프로젝트 설정 화면이 보이네요. 여기에 PostgreSQL을 추가하려면 다음과 같은 단계들을 따르면 됩니다.

---

## ✅ PostgreSQL 추가 방법 (Render 기준)

### 1. **Render에서 PostgreSQL 인스턴스 생성**

1. Render 대시보드 → 왼쪽 상단 "New +" 버튼 클릭
    
2. **"Database"** 선택
    
3. **PostgreSQL** 선택 후, 아래 설정
    
    - **Name**: `lif-db` (예시)
        
    - **Region**: 가까운 지역 선택
        
    - **Plan**: Free 또는 원하는 요금제 선택
        
    - **Database Name, User, Password**: 자동 생성되며 나중에 `.env`에 넣어야 함
        

> 생성되면 Render가 DB 접속 정보(호스트, 포트, DB명 등)를 보여줍니다.

---

### 2. **FastAPI 쪽 `.env` 또는 환경 변수에 DB 설정 추가**

예시:

```env
DATABASE_URL=postgresql://<user>:<password>@<host>:<port>/<dbname>
```

`.env` 파일을 사용하는 경우, `Settings > Environment > Secret Files` 또는 `Environment Variables`에서 입력할 수 있습니다.

---

### 3. **FastAPI 설정 (예시: `database.py`)**

```python
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

from dotenv import load_dotenv
import os

load_dotenv()

DATABASE_URL = os.getenv("DATABASE_URL")

engine = create_async_engine(DATABASE_URL, echo=True)
SessionLocal = sessionmaker(
    bind=engine, class_=AsyncSession, expire_on_commit=False
)
```

---

### 4. **Dockerfile / docker-compose와의 연동**

만약 `docker-compose`를 쓴다면, PostgreSQL 서비스를 추가해 연동할 수도 있어요:

```yaml
services:
  web:
    build: .
    ...
    environment:
      DATABASE_URL: postgresql://user:password@db:5432/dbname

  db:
    image: postgres:14
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: dbname
    ports:
      - "5432:5432"
```

하지만 Render는 자체적으로 DB를 관리하므로 따로 `db` 컨테이너 없이 Render에서 만든 PostgreSQL을 외부 DB로 연결하는 방식이 일반적이에요.




---

필요하다면 `.env`, `SQLAlchemy`, 혹은 `alembic` 마이그레이션 설정까지 도와드릴게요. 지금 사용하고 있는 프로젝트 구조나 ORM 종류(SQLAlchemy, Tortoise 등)도 알려주시면 더 정확하게 맞춰드릴 수 있어요.





![[Pasted image 20250407124431.png]]


```music_service.py
from bs4 import BeautifulSoup

import requests

  

class MusicService:

    def __init__(self):

        self.url = "https://smu.melon.com/chart/index.htm#"

        self.headers = {

            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",

            "Referer": "https://smu.melon.com/chart/index.htm#",

            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",

            "Accept-Encoding": "gzip, deflate, br",

            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",

            "Connection": "keep-alive",

            "Upgrade-Insecure-Requests": "1"

        }

  

    async def get_melon_chart(self):

        try:

            response = requests.get(self.url, headers=self.headers)

            response.raise_for_status()  # 요청 실패 시 예외 발생

            print(f"🔍 요청 상태 코드: {response.status_code}")

            soup = BeautifulSoup(response.text, "html.parser")

  

            # ⬇️ HTML 저장 추가

            with open("melon.html", "w", encoding="utf-8") as f:

              f.write(soup.prettify())

            print("🕷️ 멜론 차트 크롤링 시작")

            # 디버깅: HTML 일부를 확인

            print("HTML 일부:", soup.title.text if soup.title else "제목 없음")

            # 여러 선택자 시도

            tags = soup.find_all("div", class_="ellipsis rank01")

            if not tags:

                print("ellipsis rank01 클래스로 태그를 찾지 못했습니다. 다른 선택자 시도...")

                # 대체 선택자 시도

                tags = soup.select('.lst50 .rank01 a, .lst100 .rank01 a')

            print(f"찾은 태그 수: {len(tags)}")

            # ✅ 디버깅을 위해 태그 내용 출력

            if len(tags) > 0:

                print("첫 번째 태그 내용:", tags[0])

            else:

                print("태그를 찾을 수 없음 - 웹사이트 구조가 변경되었을 수 있습니다")

                # HTML 구조 파악을 위해 일부 출력

                print("HTML 구조 일부:", soup.body.prettify()[:500] if soup.body else "본문 없음")

            # ✅ Tag 객체에서 텍스트만 추출해 리스트로 저장

            titles = [tag.get_text(strip=True) for tag in tags]

            print(f"제목 목록 길이: {len(titles)}")

            for title in titles:

                print(title)

            print("🕷️ 멜론 차트 크롤링 완료")

            return titles  # ✅ 문자열 리스트만 반환

        except requests.exceptions.RequestException as e:

            print(f"요청 오류 발생: {e}")

            return []

        except Exception as e:

            print(f"크롤링 중 오류 발생: {e}")

            return []
```












#### 5달러 빠져나가는 것 확인하기 위해 사진 스크린 샷 된 순서
1. ![[Pasted image 20250407123601.png]]



### 파운데이션 vs 플랫폼

데이터베이스의 설계에 관해서는 파운데이션이다.(utilis의 내부)
외부에서 가져온 데이터를 주입이면 플랫폼이다.


좋아! `utils`를 내부용과 외부용으로 나누려는 생각은 아주 훌륭한 설계야 💡  
**유틸성 코드도 관심사에 따라 정리**하면 코드 가독성과 재사용성 모두 올라가거든 😎

---

## ✅ 1. 기준: 내부 vs 외부 utils의 정의

|구분|의미|예시|
|---|---|---|
|**내부 utils**|현재 프로젝트의 도메인/비즈니스 로직에 특화된 도구|크롤링 결과 정제, 커스텀 날짜 포맷터, 내부 데이터 구조 조작 등|
|**외부 utils**|범용적으로 사용될 수 있는 도구 (다른 프로젝트에서도 쓸 수 있음)|문자열 조작, 날짜 계산, 리스트 변환, 파일 핸들링, 로깅 등|

---

## ✅ 2. 폴더 구조 예시

```bash
utils/
├── internal/
│   ├── chart_parser.py      # 멜론 크롤링 데이터 파싱
│   ├── data_normalizer.py   # 특정 구조로 데이터 정리
│   └── __init__.py
├── external/
│   ├── date_utils.py        # 날짜 관련 함수 (ex. 오늘, 어제, 요일 등)
│   ├── string_utils.py      # 문자열 정리 함수
│   └── file_utils.py        # 파일 저장/불러오기
└── __init__.py
```

---

## ✅ 3. 예시로 나누자면

- `format_chart_data(data: List[Tag]) -> List[Dict]`  
    → 멜론 전용 정리 → `internal/chart_parser.py`
    
- `get_today_string(format="%Y-%m-%d")`  
    → 어디서든 쓸 수 있음 → `external/date_utils.py`
    
- `slugify("멜론 차트🎵") -> "melon-chart"`  
    → 문자열 유틸 → `external/string_utils.py`
    

---

## ✅ 폴더 이름 추천

|목적|폴더 이름 추천|
|---|---|
|내부 비즈니스 유틸|`internal`, `core_utils`, `domain_utils`|
|외부 범용 유틸|`external`, `common_utils`, `shared_utils`|

👉 가장 깔끔하게는 `internal/`, `external/` 추천!

---

## ✨ 예시 사용

```python
# 내부용
from utils.internal.chart_parser import parse_chart

# 외부용
from utils.external.date_utils import get_today_string
```

---

필요하다면, `__init__.py`로 묶어서 `utils.parse_chart()`처럼 import 경로도 더 예쁘게 만들어줄 수 있어.  
원하면 그 부분도 도와줄게 😊

---

📌 **한 줄 요약**:

- 내부: 프로젝트 전용 로직용 유틸
    
- 외부: 범용 툴  
    → `utils/internal/`, `utils/external/` 이렇게 폴더 구성하고 시작해보자!




api --> platform(외부 utils)
api --> foundation(내부 utils)



foundation : "클래스 안에서 혼자 쓰는 장치들", "핵심 로직 뇌구조"
- core - 핵심 비즈니스 로직 (외부와 격리된 로직만!), 클래스 안에서 쓰는 것이다.
	- abstraction: 부모자식 상속 구조 정리
	- config: 앱 설정값 관리(예: `.env` 읽기, 설정 클래스 등)
	- decorator: 공통 데코레이터 (ex. 로깅, 예외 처리, 인증 체크)
	- enums:
- infrastructure - DB를 놔두는 곳이다. 예시: 도시난방, .....
	- database
	- logger: 외부에서 고치는 경우...바깥에서 로그 볼 수 있다.
	- security: 토큰을 넣어 놓는 곳 이다. 아파트 동 안에서 쓰이는 곳이다. 
- utils -잔잔바리 들... 내가 코딩해서 쓰는데, 현저하게 가치가 떨어지는 코디를 쓰는 곳


platform: 필요할 때만 쓰는 것이다.
- adapters: 외부에서 필요할 때만 연결하는 것
	- aws
	- google
	- naver: 네이버 로그인 연결하는 것

utils


railway에 들어가봤더니,  railway에서 제공하는 데이터가 너무 구려서 그것을 안쓰고, fastAPI 안에서 데이터를 만들어서  DB를 설치하려고 한다. 결론, 그리고 DB 안에 들어와 있는 상태이다. 

질문: 현재 local에서 railway 컨테이너로 접속하고 싶어. docker exec -it crawler-crawler-api-1 bash -c "PGPASSWORD=YLkbHpjtkasEeLizyLxNUvtdPSlkpNaa psql -h crossover.proxy.rlwy.net -U postgres -p 27041 -d railway" 이거를 참조해서 명령문을 올바르게 수정해줘. DATABASE_PUBLIC_URL=postgresql+asyncpg://postgres:KdsPNXKRajZFKktXktTFviRyIvAGaOAc@switchyard.proxy.rlwy.net:48892/railway이건 내 코드이고, 여기에서 비번을 찾아서 해줘.




이제 song.py 모델을 Railway 데이터베이스에 연결하는 엔티티로 변환하고, melon_repository.py에 커맨드 패턴을 사용하여 생성자 방식으로 구현한 리포지토리를 추가했습니다. 레일에이에서 제공하는 데이터가 있는데, 내마음대로 인서트가 안되서 데이터 베이스를 따로 만든다. 

구현된 기능을 요약하면 다음과 같습니다:

1. Song 모델을 SQLAlchemy ORM 엔티티로 변환하여 Railway PostgreSQL 데이터베이스와 연동

2. 커맨드 패턴을 사용하여 MelonRepository 클래스 구현

3. 생성자 방식으로 노래 정보를 저장하는 insert_song 메서드 구현

4. API 라우터에 노래 정보를 생성하고 조회하는 엔드포인트 추가

5. __init__.py 파일들에 불필요한 코드는 제거하고 주석만 남김

이 설정을 통해 Railway 데이터베이스에 노래 정보를 저장하고 조회할 수 있습니다.
