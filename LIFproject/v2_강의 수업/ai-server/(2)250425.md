
- 참고 사이트: https://wikidocs.net/222895
- 피처 엔지니어링 기법 - 전처리 과정을 의미함.
##### 알고리즘 8개 사용
- 선형 회귀로 처리해줘(linear regression) --> 컨텐츠를 모를 때 쓰는 방식, 연속적이고, 범주, 카테고리.....연속적인것은 실수 범주, 확률로 해석해서 분류한다.
	- 선형: 두 점을 연결하는 선 사이에 분포가 된 것을 보고 예측할 수 있다. 그 점 도 예측할 수 있게 한다. 이건 미래에 대한 예측임을 알 수 있다. 
	- 회귀(통계에서 회귀):  
-  로지스틱 회귀로 처리해줘
	- 
- k- 최근접 이웃
	- 
- 나이브 베이즈
- 결정 트리
- 랜덤 포레스트
- XGBoost
- LightGBM


차원: 변수의 갯 수(머신러닝과 딥러닝)

차원이 feature이다. feature의 갯수로 선형회귀와 로지스틱 회귀로 차이를 둔다. 선형회귀는 feature가 하나이다. 로지스틱 회귀는 feautre가 복수이다. 

feature의 갯 수가 0개 면 선형으로 움직인다.

#### 로지스틱 회귀: 
- S자 곡선: 로지스틱 회귀에서는 **결과값을 0~1 사이의 확률로 바꾸기 위해** **시그모이드 함수(sigmoid function)**라는 **S자 곡선**을 사용해. **S자 모양 곡선**으로 확률을 매끄럽게 표현하는 것을 의미함. **시그모이드 함수**를 사용한다. 
-  다차원 방식 함수는 시그모이드 함수를 사용한다.


##### 하이퍼파라미터: 
- 외부에서 입력되는 값을 경로를 통해 연결되는 것을 의미함. 주입이다(하나가 죽으면 나머지도 다 죽는다). 
- 하이퍼파라미터는 의존성 주입을 가지고 있다. 


##### 선형 회귀 방식과 로지스틱 회귀 방식
- 1차원 방식 함수는 linear라고 한다. 다차원 방식 함수는 시그모이드 함수를 사용한다.


#### k- 최근접 이웃(복수)과 나이브 베이즈(단수)의 차이점: 단수냐 복수냐의 차이이다. 
##### k - 최근접 이웃(KNN)
- k : 변수의 갯수를 의미한다. 
- 새로운 데이터를 예측할 때, 가장 가까운 K개의 이웃(객체와 객체사이 가까워서 이웃이라고 한다.)을 참고해서 판단하겠다”는 뜻이야.
- 결정을 내릴 때 참고하는 기준의 수를 가지고 단수와 복수로 나뉜다. 여기서 k-최근접 이웃은 결정을 내릴 때 참고하는 기준의 수가 복수가 있다. 

##### 베이즈 정리(옛날에 나온 방식)
- *기존 믿음 * 정보가 나타날 가능성* = 최종 판단 확률
- **사전 확률**을(일단 믿고 있는 확률) 가지고, **사후 확률**(새로운 정보를 보고 나서 바뀐 확률)을 결정짓는다. 
- 특정 클래스가 맞다고 가정했을 때, 이 증거가 얼마나 자연스러운지를 말하는 것을 **우도**라고 한다.
- 자연스럽다? 이 말은 어떤 클래스에서 그 특징이 잘 나올 수 있음
	- 예시) 스팸: 무료, 1억원, 이런 단어들이 많이 등장함 --> 우리는 이것을 스팸이라고 부른다. 
##### 나이브 베이즈 정리
- 베이즈 정리를 “단순화해서 분류 문제에 적용한 머신러닝 알고리즘”
- 입력된 여러 특징(feature)들이 **서로 독립이다!** 라고 **너무 순진하게 가정**한다.
- 각 단어가 서로 영향을 안 준다고 **가정**하고,  **베이즈 정리를 단순히 곱해 적용**하는 것 = 나이브 베이즈 모델
- 


### 8개 알고리즘 중에서 타이타닉 생존률을 구할 때, 어떤 알고리즘을 써야 정확도가 높아지는지 서비스 구현하기

- 난 지금 ai-service를 사용하고 있고, 지금 사이킷 런을 사용하고 있어. 그리고 난 DB를 사용하지 않아. 그리고 스레드 순서는 main.py --> controller.py --> service.py --> schema.py이야.  서브 라우터를 없애고, controller를 바로 호출하는 형태로 하고 있음. 알고리즘 8개 가운데 먼저 사용할 알고리즘은 RandomForestClassifier로 시작하기. 그리고 나서 성능이 어느 정도 나왔을 때, XGBClassifier로 갈아타기.

1단계: 내가 정리한 내용을 토대로 표를 구현해 봤음
![[Pasted image 20250425122606.png]]

2. 추가로 해야할 일(실전 기준)

![[Pasted image 20250425122701.png]]

### 1단계 `RandomForestClassifier`를 사용하는 이유
#### 타이타닉 데이터의 특성은?

- 범주형 데이터 (`Sex`, `Embarked`, `Title`)
    
- 수치형 데이터 (`Age`, `Fare`)
    
- 결측치 있음
    
- 변환된 파생 피처도 포함됨 (e.g. `AgeGroup`, `FareGroup`)
    

➡ 이런 다양한 형태의 데이터를 **한 번에 잘 처리할 수 있는 모델**이 Random Forest야.

![[Pasted image 20250425122954.png]]

#### 설명력과 피처 중요도 파악 가능

- 너가 전처리한 `Title`, `Gender`, `AgeGroup` 중  **어떤 게 생존률 예측에 가장 중요할까?**

- ➡ `RandomForestClassifier`는 `.feature_importances_` 속성으로  **각 피처의 중요도(영향력)**를 자동으로 계산해줘!



#### k-fold 와 n-fold
k- fold와 n- fold는 검증을 하기 위한 테스트 횟수를 의미한다.
- k- fold: 
	- 여기서 k는 객체의 갯수를 의미함.
	- k는 인간 몇명을 의미하는지 주는 것을 의미함

- n- split:
	- 여기서 n은 횟수를 의미함. 


shuffle = True
- 기존에 테스트 했던 것까지 다시 테스트 되었던 것도 다시 넣어서 테스트 하는 것을 의미함.

shuffle = false
- 기존에 테스트 했던  것은 빼고 그 나머지만 테스트 하는 것을 의미함.

random_state 란, 무작위 작업을 할 때, 결과를 고정시켜주는 값이야. 테스트 하기 위한 **똑같은 문제**를 주는 것이다.
random_state = 0 은 0이라는 문제를 준 것이다. 즉, 0번 문제만 푼다는 것이다. 







