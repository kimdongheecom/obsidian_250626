
딥러닝(학습)에서 파일은 모델이다.

최초의 모델: 

머신러닝에서 파일은 학습된 모델이다. 예: .xml, .chkt
딥러닝 모델에서 CNN이 있다.

CNN은 딥러닝 모델의 구조이자, 학습된 파라미터를 포함한 모델 그 자체이다.



NN과 딥러닝 MODEL

- dnn은 딥러닝의 모델이다. 
- 모델은 구조이다.

**머신러닝에서 모델은 파일이고, 딥러닝에서 모델은 구조(파일에다가 구조까지 포함된 개념이라고 생각하기)이다.**


CNN으로 하면 정확도가 올라간다. -->얀루큰이 개발하였다.

##### 얀 르쿤의 우편번호 자동 인식기(자동 분류 시스템을 만들었다.)
- **미국 우체국에서 우편물 자동 분류기**를 연구하던 중, **우편번호를 손으로 쓴 글씨(필기체)로 인식하는 문제**를 해결하고 싶었습
니다.
- **필기 숫자 인식(MNIST)** 데이터에 CNN을 처음 성공적으로 적용하였다. 

- DNN에서는 오차가 거의 없다. 정확도가 거의 99%이다.


#### 딥러닝의 4대 천왕(인공지능 분야에서)

- 제프리 힌턴 (Geoffrey Hinton) - 영국  
	-  MLP, 역전파 알고리즘  
		- 역전파 알고리즘 이란?  
			- 모델의 depth가 깊어질수록, 모델의 층이 많아질수록 모델의 가중치의 수는 기하급수적으로 많이 늘어남.
- 얀 르쿤 (Yann LeCun) - 프랑스  
	- CNN(합성곱 신경망) - 이미지와 같은 그리드 형태 데이터 처리에 매우 효과적인 CNN 구조  
					- 컴퓨터 비전 분야에서 엄청난 성능 개선을 이룸.
- 요수아 벤지오(Yoshua Bengio) - 프랑스  
	- RNN & NLP : Word Embeddig과 신경망 기반 언어 모델 연구에 중요한 기여  
	- _GAN_(Generative Adversarial Nets) : AI 그림 생성의 시초  
		- 기계 번역, 챗봇, 텍스트 생성 등 현대 NLP 기술 발전에 지대한 영향
- 앤드루 응(Andrew Ng) - 홍콩  
	-  2012년 유튜브 동영상에서 고양이 얼굴을 스스로 학습하는 신경망 연구는 딥러닝의 가능성을 대중에게 각인시키는 중요한 계기,  **Coursera**

#### 딥러닝의 4대 천왕....비유하자면, 
- 제프리 힌턴 → 신경망의 **근본 철학자**
    
- 얀 르쿤 → 시각 분야의 **건축가**
    
- 요슈아 벤지오 → 언어/시퀀스의 **탐험가**
    
- 앤드루 응 → 대중을 위한 **전도사**


CNN 구조(Layer)의 도입

- layer: 서비스 컨트롤러 들을 말한다.

###### api의 구조
- mvc
- msa
- 모놀리식


과적합: 
###### cnn의 구조
- convolutional layer(합성곱 계층): 특징 맵을 추출한다. 
	- **특징 맵 = CNN이 이미지에서 의미 있는 정보를 숫자로 추출해낸 결과물**입니다. 
	- 이미지의 특징(숫자)을 추출한다. 이미지를 숫자의 행렬로 바꿔서 이해하는 것을 의미함.
		- 여기서 특징이라는 것은 이미지, 음성, 텍스트 등에서 패턴, 경향, 구조 등 중요한 정보를 수치로 표현한 것을 의미한다.
- pooling layer(폴링 계층):  
	- 크기를 줄이고 불변성 확보 (압축 및 저장) - 영속성이 저장이다. 저장은 변하지 않는 것을 말함. 
- fully connected layer(완전 연결 계층 - 전결합층):


CNN 
- -> 이미지를 부분별로 픽셀 단위로 쪼개는 것? 을 말하는거다.



합성곱 레이어

파라미터

in_channel: 입력 채널 수
	channel: 입력받고 출력받는 통로

out_channel: 출력 채널 수
kernal_size: 커널은 가중치 행렬를 의미한다. 커널들이 여러개 적용되서.... 필터를 말한다. 커널의 집합은 필터이다. 커널마다 
stride: 한 칸씩 움직인다.
padding: 가장자리를 알려주는 ,,,,여백에서 읽으면 오류가 발생하니까....



##### 활성화 함수: 핵심 기능을 담당하는 함수를 의미한다. 쓸모있는 것만.....

- **시그모이드 함수**:** 스팸이냐 아니냐에 따라....이진분류이면 시그모이드 함수를 쓴다. 기울기가 0인 상태일 때 쓴다.
- **leru:** 기울기 소실 문제를 줄여주는 활성화 함수이다. 활성화 된 함수의 수를 줄이는 것이다. 0 이하의 숫자들은 다 제거한다. positive한 데이터만 남겨 놓는다. 기울기가 차감될 때,,즉 중간에서 쓴다.
- **소프트 맥스:** 확률로서 하나 뽑아 내는 것을 의미한다. 기울기가 0인 상태일 때 쓴다.

자연어를 기계어로 변환해 주는 것을 변환기라고 한다.이걸 **transform**이라고 한다.



#### RNN vs LSTM vs GRU
##### RNN과 lstm 그리고 gru는  모두 시퀀스 데이터를 처리하는 딥러닝 모델이다.
- 시퀀스 모델은 
- 입력과 출력 사이에, 은닉층을 갖고 있는데, 은닉층은 상태를 갖고있다. 이때 RNN이 쓰인다.
**RNN**인데 상태의 기간이 길게 저장된 것을 **LSTM**이라고 한다.

저장되어 있는 스냅 샷이 작기 때문에 짧게 저장되어 있다.--> 단기 상태에 있다.


**GRU**: 롱텀이 상태가 길어지면 느려지니까......줄여주는 것을 의미함. "안녕"뒤에 하세요...나올 수 있게끔.....


#### RNN계열 vs 트랜스포머 계열

|항목|**RNN / LSTM / GRU**|**트랜스포머 (Transformer)**|
|---|---|---|
|**데이터 처리 방식**|순차적으로 처리 (하나씩)|전체 시퀀스를 **한꺼번에 병렬 처리**|
|**의존성 처리**|가까운 과거만 잘 기억|**멀리 떨어진 단어 간 관계도 잘 기억**|
|**병렬 처리**|불가능 (시간 순서대로만)|가능 (GPU 활용 최적화)|
|**대표 구조**|순환 구조 (Recurrent)|**Self-Attention 구조**|
|**한계**|긴 시퀀스 학습 어려움, 속도 느림|빠르고 정확, 학습 효율 높음|
|**주로 쓰인 시기**|~2017 이전|2017 이후 (GPT, BERT 등 대세)|

- **RNN/LSTM**:  
    말 한 마디씩 순서대로 들어야 의미 파악함  
    → "나는... 오늘... 기분이... 좋다"
    
- **트랜스포머**:  
    문장을 통째로 보고 **‘좋다’가 왜 나왔는지 앞뒤를 다 고려**함  
    → “기분이 좋다”가 핵심이라는 걸 빠르게 파악

#### 트랜스포머 기반 대표 모델들(RNN 개선된 브랜드)
- 디코더 할 때, 아래 주

|이름|설명|
|---|---|
|**GPT (OpenAI)**|ChatGPT 모델, 문장 생성에 강함|
|**BERT (Google)**|문장 이해/분류에 강함|
|**T5 (Google)**|텍스트를 입력→출력 문제로 통일 (번역, 요약 등)|
|**BART (Meta)**|GPT + BERT 구조 혼합 (텍스트 복원, 생성)|
|**LLAMA (Meta)**|오픈소스 대형 언어 모델|
|**PaLM, Gemini (Google)**|대형 모델 계열로 확장 중|
#### RNN, LSTM, GRU의 관계 (크기 비교)
- LSTM/GRU는 **성능과 기억력 향상을 위해 등장한 RNN의 개선형**이에요.

| 계층 구조                    |
| ------------------------ |
| 🧠 RNN (기본 구조)           |
| ↳ 🧠 LSTM (장기 기억 강화)     |
| ↳ 🧠 GRU (LSTM보다 가볍고 빠름) |


#### 코퍼스: 언어 모델이 공부하는 교과서
- 명사 위주로만 나와있는 딕셔너리...자연어 사전이다.


##### 원- 핫 인코딩 vs 워드 임배딩

- 원-핫 인코딩의 개선안 : 워드 임배딩
- 원핫인코딩으로 만들어진 것들을 모아놓은 것을 워드 임베딩이라고 한다. 원핫인코딩은 0과 1로 되어있다.정수이다.

- 워드 임배딩: 실수로 되어있고, 확률로 나온다. 임베딩은 유사한 것을 모아 논 것을 의미한다. 예를 들어, i일 경우, he, she, they를 가지고 있는 임베딩을 가지고 온다라고 할 수 있다. 

##### sparse vs dense
- sparse: 희소하다

- dense: 밀집되어 있다.

토크나이저 = 토큰화: 명사만 남겨두고 조사는 뺀다. 예: "아버지가 방에 들어가셨습니다" 에서 아버지, 방....


##### 센텐스피스: 토큰화 작업 중 하나이다. 센턴스를 조각시키는 것을 의미한다.

##### 허깅 페이스: 자연어 처리(NLP) 플랫폼 회사이다.


인코더와 디코더 두개 다 써야한다.(영한 사전, 한영사전 두개 다 필요하니까...)

- 인코더: 인코딩 해주는 것
	- 인코딩: 자연어 --> 기계어

- 디코더: 디코딩 해주는 것()
	- 디코딩: 기계어 --> 자연어

bert는 구글 꺼이다.



**프롬프팅**(오늘의 과제...인사말..나오게끔... 안녕하세요 하면 감사합니다까지 나오게끔....오늘의 목표)
- 내가 한국어로 된 챗봇을 제작하려고 해. 당연히 RNN을 쓸꺼야. 허깅 페이스에서 한국어가 잘 훈련된 모델을 너가 추천해줘...하고나서.. 아래 링크를 추천해줌. https://huggingface.co/skt/kobert-base-v1이것을 선택했을 때, 한국어 인사를 하는 챗봇을 msa구조로 개발하려고 해. 이때 ai-server를 사용하는 방법을 간단하게 소개해줘.


### 시퀀스 투 시퀀스: 
- 질문과 대답으로 구성해서 챗봇을 만들어서 ,,,,사용하는 것을 의미한다.

입력 시퀀스와 출력 시퀀스...



##### CNN과 RNN의 차이

|항목|**CNN (Convolutional Neural Network)**|**RNN (Recurrent Neural Network)**|
|---|---|---|
|**주로 쓰이는 분야**|이미지, 영상 처리|언어, 음성, 시계열 데이터|
|**입력 구조**|2차원 (예: 이미지 픽셀)|순차적 데이터 (문장, 시간 흐름)|
|**핵심 기능**|공간적인 패턴 감지 (엣지, 윤곽 등)|시간적 순서와 흐름 이해|
|**예시**|고양이 이미지 분류, 얼굴 인식|번역, 챗봇, 감정 분석, 주가 예측|


##### 어텐션(attention)
- 이 전까지의 과정을 검토하는 것을 의미한다. 쳇 지피티에서 우리가 계속 대화 했던 내용들을 검토해서.....그래서 쳇 지피티는 어텐션 기법을 가지고 있다라고 말할 수 있다.
	- time이 들어가면 상태를 생각하면 된다.

#### faiss -  라이브러리
- 임배딩을 쓴다는 것은 faiss라이브러리를 사용하면 된다.


자연어 처리할 때, bert와 gpt 중에 골르면 된다. gpt에도 여러 종류가 있다. GPT 기반 모델은 **텍스트 생성 능력이 뛰어나서 챗봇 제작에 매우 적합**하고,  **로컬에서 무료로 설치 가능한 버전**도 다양하게 존재합니다.

| 모델 이름                            | 크기          | 언어        | 특징                   |
| -------------------------------- | ----------- | --------- | -------------------- |
| **GPT2 (OpenAI)**                | 124M ~ 1.5B | 영어        | 완전 공개, 빠름, 연습용 좋음    |
| **KoGPT2 (KakaoBrain)**          | 125M        | 한국어       | 한국어 GPT2 버전, 가볍고 빠름  |
| **KoAlpaca-Polyglot** (by Beomi) | 12.8B       | 한국어 + 다국어 | 명령어/프롬프트 응답 특화       |
| **OpenChatKit, OpenAssistant**   | 6B~13B      | 다국어       | 챗봇 지향 모델, 로컬 챗GPT 대안 |
| **Mistral-7B-Instruct**          | 7B          | 영어        | 고성능, RAM 16GB 이상 권장  |
| **Phi-2 (MS)**                   | 2.7B        | 영어        | 소형 고성능 GPT 스타일 모델    |
| **TinyLlama**                    | 1.1B        | 영어        | 초경량, 노트북에서도 작동 가능    |
|                                  |             |           |                      |

##### mnist_service.py를 만들어서, mnist 만들기.... 

mnist란?
- 손으로 쓴 숫자(0~9)의 흑백 이미지를 모아 만든 손글씨 숫자 이미지 데이터 셋이다.
	- 여기서 데이터 셋은 AI나 머신러닝 모델이 학습하거나 테스트할 때 사용하는 데이터 모음을 의미한다. 즉, 데이터셋(dataset)**은 **컴퓨터가 학습하거나 평가할 수 있도록 정리된 “데이터의 집합을 의미한다.
	

(프롬프팅)
CNN을 사용해서 사진에 적혀있는 숫자를 인식하려고해. 나는 지금 msa구조에서 파일 업로드해서 숫자를 인식하게 할꺼야. 근데 이미 파일 업로드 하는 방식은 갖춰졌어.


```
import os

from fastapi import APIRouter, File, UploadFile, Path, Query, Body

from fastapi.responses import JSONResponse

from pydantic import BaseModel

import shutil

import logging

import cv2

import matplotlib.pyplot as plt

from tensorflow import keras

import numpy as np

  

router = APIRouter()

logger = logging.getLogger("tf_main")

  

# 업로드 디렉토리와 출력 디렉토리를 app 내부로 고정

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")

OUTPUT_DIR = os.path.join(BASE_DIR, "output")

os.makedirs(UPLOAD_DIR, exist_ok=True)

os.makedirs(OUTPUT_DIR, exist_ok=True)

logger.info(f"파일 업로드 디렉토리: {UPLOAD_DIR}")

logger.info(f"파일 출력 디렉토리: {OUTPUT_DIR}")

  

# MNIST 관련 요청 모델

class MnistSampleRequest(BaseModel):

    index: int = 100  # 기본값은 100번째 이미지

    filename: str = "mnist_sample.png"  # 기본 파일명

    add_noise: bool = False  # 노이즈 추가 여부

  

# MNIST 샘플 이미지 생성 엔드포인트 (GET)

@router.get("/mnist-sample")

async def get_mnist_sample():

    """

    MNIST 데이터셋에서 100번째 이미지를 반환합니다.

    이미지는 mnist 디렉토리에 mnist_sample.png 파일로 저장되고, 레이블은 JSON으로 반환됩니다.

    **Returns**:

    - **label**: 이미지의 레이블 (숫자 0-9)

    - **image_path**: 저장된 이미지 파일 경로

    """

    try:

        # MNIST 데이터셋 로드

        mnist = keras.datasets.mnist

        (train_images, train_labels), (_, _) = mnist.load_data()

        # 100번째 이미지 선택

        mnist_idx = 100

        image = train_images[mnist_idx]

        label = int(train_labels[mnist_idx])

        # 이미지 파일 저장 경로 설정

        mnist_dir = os.path.join(OUTPUT_DIR, "mnist")

        os.makedirs(mnist_dir, exist_ok=True)

        image_path = os.path.join(mnist_dir, "mnist_sample.png")

        # Matplotlib을 사용하여 이미지 저장

        plt.figure(figsize=(5, 5))

        plt.imshow(image, cmap='gray')

        plt.axis('off')  # 축 제거

        plt.savefig(image_path, bbox_inches='tight', pad_inches=0)

        plt.close()

        logger.info(f"MNIST 샘플 이미지(인덱스: {mnist_idx}, 레이블: {label})가 {image_path}에 저장되었습니다.")

        # 응답 반환

        return {

            "label": label,

            "image_path": image_path

        }

    except Exception as e:

        logger.error(f"MNIST 샘플 이미지 생성 오류: {str(e)}")

        return JSONResponse(

            content={"error": f"MNIST 샘플 이미지 생성 중 오류 발생: {str(e)}"},

            status_code=500

        )

  

# MNIST 샘플 이미지 생성 엔드포인트 (POST)

@router.post("/mnist-sample")

async def post_mnist_sample(request: MnistSampleRequest = Body(...)):

    """

    MNIST 데이터셋에서 지정된 인덱스의 이미지를 반환합니다.

    **Request Body**:

    - **index**: 이미지 인덱스 (0-59999)

    - **filename**: 저장할 파일명

    - **add_noise**: 노이즈 추가 여부

    **Returns**:

    - **label**: 이미지의 레이블 (숫자 0-9)

    - **image_path**: 저장된 이미지 파일 경로

    - **has_noise**: 노이즈 추가 여부

    """

    try:

        # MNIST 데이터셋 로드

        mnist = keras.datasets.mnist

        (train_images, train_labels), (_, _) = mnist.load_data()

        # 인덱스 범위 확인

        if request.index < 0 or request.index >= len(train_images):

            return JSONResponse(

                content={"error": f"유효하지 않은 인덱스: {request.index}, 0-{len(train_images)-1} 범위 내에서 지정해주세요."},

                status_code=400

            )

        # 지정된 인덱스의 이미지 선택

        image = train_images[request.index].copy()  # 원본 데이터 변경 방지를 위한 복사

        label = int(train_labels[request.index])

        # 노이즈 추가 (요청된 경우)

        has_noise = False

        if request.add_noise:

            noise = np.random.normal(0, 15, image.shape)

            image = np.clip(image + noise, 0, 255).astype(np.uint8)

            has_noise = True

        # 이미지 파일 저장 경로 설정

        mnist_dir = os.path.join(OUTPUT_DIR, "mnist")

        os.makedirs(mnist_dir, exist_ok=True)

        # 파일명에 레이블과 노이즈 정보 추가

        filename_base = os.path.splitext(request.filename)[0]

        filename_ext = os.path.splitext(request.filename)[1] or ".png"

        noise_suffix = "_noise" if has_noise else ""

        final_filename = f"{filename_base}_label{label}{noise_suffix}{filename_ext}"

        image_path = os.path.join(mnist_dir, final_filename)

        # Matplotlib을 사용하여 이미지 저장

        plt.figure(figsize=(5, 5))

        plt.imshow(image, cmap='gray')

        plt.axis('off')  # 축 제거

        plt.savefig(image_path, bbox_inches='tight', pad_inches=0)

        plt.close()

        logger.info(f"MNIST 샘플 이미지(인덱스: {request.index}, 레이블: {label}, 노이즈: {has_noise})가 {image_path}에 저장되었습니다.")

        # 응답 반환

        return {

            "label": label,

            "image_path": image_path,

            "has_noise": has_noise

        }

    except Exception as e:

        logger.error(f"MNIST 샘플 이미지 생성 오류: {str(e)}")

        return JSONResponse(

            content={"error": f"MNIST 샘플 이미지 생성 중 오류 발생: {str(e)}"},

            status_code=500

        )

  

@router.post("/upload")

async def upload_file(file: UploadFile = File(...)):

    file_location = os.path.join(UPLOAD_DIR, file.filename)

    logger.info(f"파일 업로드 시작: {file.filename}, 저장 위치: {file_location}")

    try:

        with open(file_location, "wb") as buffer:

            shutil.copyfileobj(file.file, buffer)

        logger.info(f"파일 업로드 성공: {file.filename}")

        if os.path.exists(file_location):

            file_size = os.path.getsize(file_location)

            logger.info(f"파일 저장 확인: {file_location}, 크기: {file_size} bytes")

        else:

            logger.error(f"파일이 저장되지 않음: {file_location}")

        return JSONResponse(content={"filename": file.filename, "message": "파일 업로드 성공!", "path": file_location})

    except Exception as e:

        logger.error(f"파일 업로드 실패: {str(e)}")

        return JSONResponse(content={"error": str(e)}, status_code=500)

  

@router.get("/mosaic")

async def mosaic_all_uploads():

    cascade = os.path.join(BASE_DIR, 'data', 'haarcascade_frontalface_alt.xml')

    face_cascade = cv2.CascadeClassifier(cascade)

    processed_files = []

    failed_files = []

  

    for filename in os.listdir(UPLOAD_DIR):

        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):

            img_path = os.path.join(UPLOAD_DIR, filename)

            img = cv2.imread(img_path)

            if img is None:

                failed_files.append(filename)

                continue

            face = face_cascade.detectMultiScale(img, minSize=(30,30))

            if len(face) == 0:

                logger.error(f'얼굴인식 실패: {filename}')

                failed_files.append(filename)

                continue

            for (x, y, w, h) in face:

                logger.info(f'{filename} 얼굴의 좌표 = {x}, {y}, {w}, {h}')

                # 얼굴 영역 잘라내기

                face_img = img[y:y+h, x:x+w]

                # 모자이크(픽셀화) 적용

                mosaic = cv2.resize(face_img, (16, 16), interpolation=cv2.INTER_LINEAR)

                mosaic = cv2.resize(mosaic, (w, h), interpolation=cv2.INTER_NEAREST)

                # 원본 이미지에 다시 붙이기

                img[y:y+h, x:x+w] = mosaic

            output_path = os.path.join(OUTPUT_DIR, f"{os.path.splitext(filename)[0]}-face.png")

            cv2.imwrite(output_path, img)

            processed_files.append(output_path)

  

    return JSONResponse(content={

        "message": "모자이크 처리 완료",

        "processed_files": processed_files,

        "failed_files": failed_files

    })
```